{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "asl.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPE7cC5d6JQ5p90sUsas0Vi",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielyoon-maker/ASL/blob/master/asl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJPa2fe0tl4E"
      },
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bseVzQ4Y9vb6"
      },
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_CeYnYndeib"
      },
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JP0QeAzdi2j",
        "outputId": "15763f84-330a-4131-a1e3-83cf4546d354"
      },
      "source": [
        "! kaggle datasets list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "ref                                                         title                                              size  lastUpdated          downloadCount  \n",
            "----------------------------------------------------------  ------------------------------------------------  -----  -------------------  -------------  \n",
            "gpreda/reddit-vaccine-myths                                 Reddit Vaccine Myths                              237KB  2021-11-21 16:54:23          16110  \n",
            "crowww/a-large-scale-fish-dataset                           A Large Scale Fish Dataset                          3GB  2021-04-28 17:03:01           9724  \n",
            "imsparsh/musicnet-dataset                                   MusicNet Dataset                                   22GB  2021-02-18 14:12:19           4457  \n",
            "dhruvildave/wikibooks-dataset                               Wikibooks Dataset                                   2GB  2021-10-22 10:48:21           3555  \n",
            "promptcloud/careerbuilder-job-listing-2020                  Careerbuilder Job Listing 2020                     42MB  2021-03-05 06:59:52           2737  \n",
            "fatiimaezzahra/famous-iconic-women                          Famous Iconic Women                               838MB  2021-02-28 14:56:00           1909  \n",
            "nickuzmenkov/nih-chest-xrays-tfrecords                      NIH Chest X-rays TFRecords                         11GB  2021-03-09 04:49:23           1638  \n",
            "mathurinache/twitter-edge-nodes                             Twitter Edge Nodes                                342MB  2021-03-08 06:43:04           1316  \n",
            "alsgroup/end-als                                            End ALS Kaggle Challenge                           12GB  2021-04-08 12:16:37           1105  \n",
            "simiotic/github-code-snippets                               GitHub Code Snippets                                7GB  2021-03-03 11:34:39            504  \n",
            "mathurinache/the-lj-speech-dataset                          The LJ Speech Dataset                               3GB  2021-02-15 09:19:54            490  \n",
            "coloradokb/dandelionimages                                  DandelionImages                                     4GB  2021-02-19 20:03:47           1023  \n",
            "imsparsh/accentdb-core-extended                             AccentDB - Core & Extended                          6GB  2021-02-17 14:22:54            178  \n",
            "stuartjames/lights                                          LightS: Light Specularity Dataset                  18GB  2021-02-18 14:32:26            205  \n",
            "landrykezebou/lvzhdr-tone-mapping-benchmark-dataset-tmonet  LVZ-HDR Tone Mapping Benchmark Dataset (TMO-Net)   24GB  2021-03-01 05:03:40            232  \n",
            "nickuzmenkov/ranzcr-clip-kfold-tfrecords                    RANZCR CLiP KFold TFRecords                         2GB  2021-02-21 13:29:51            162  \n",
            "datasnaek/youtube-new                                       Trending YouTube Video Statistics                 201MB  2019-06-03 00:56:47         158650  \n",
            "zynicide/wine-reviews                                       Wine Reviews                                       51MB  2017-11-27 17:08:04         148965  \n",
            "datasnaek/chess                                             Chess Game Dataset (Lichess)                        3MB  2017-09-04 03:09:09          25302  \n",
            "residentmario/ramen-ratings                                 Ramen Ratings                                      40KB  2018-01-11 16:04:39          30070  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c8e8_dvdoiL",
        "outputId": "d1ea838f-4968-4157-ed2b-b17720289a42"
      },
      "source": [
        "! kaggle datasets download grassknoted/asl-alphabet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading asl-alphabet.zip to /content\n",
            " 98% 1.01G/1.03G [00:09<00:00, 109MB/s] \n",
            "100% 1.03G/1.03G [00:09<00:00, 117MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjOucYc8d52D"
      },
      "source": [
        "%%capture\n",
        "! unzip asl-alphabet.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7Or8seseqpe"
      },
      "source": [
        "#prep\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_rG1Fsj4NJX",
        "outputId": "03c8392e-eb6f-4b2a-b56f-becbb60f519b"
      },
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  './asl_alphabet_train/asl_alphabet_train/',\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  color_mode = 'grayscale',\n",
        "  seed=123,\n",
        "  image_size=(200, 200),\n",
        "  batch_size=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 87000 files belonging to 29 classes.\n",
            "Using 69600 files for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSIsdzZQ6Gvg",
        "outputId": "2f3c375b-5a31-4131-a55d-6c8e2ef8437a"
      },
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  './asl_alphabet_train/asl_alphabet_train/',\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  color_mode = 'grayscale',\n",
        "  seed=123,\n",
        "  image_size=(200, 200),\n",
        "  batch_size=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 87000 files belonging to 29 classes.\n",
            "Using 17400 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UA8L55FA6RVD",
        "outputId": "0d5390f8-95fb-492b-eeef-4aa19dee1b78"
      },
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpkJy56I6p0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "046ef996-5de8-4717-80de-4e167b5f984b"
      },
      "source": [
        "num_classes = len(class_names)\n",
        "#defining the model\n",
        "\n",
        "from keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D\n",
        "from keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# number of possible label values\n",
        "# Initialising the CNN\n",
        "model = Sequential()\n",
        "\n",
        "# 1 - Convolution\n",
        "model.add(Conv2D(64,(3,3), padding='same', input_shape=(200, 200, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# 2nd Convolution layer\n",
        "model.add(Conv2D(128,(5,5), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# 3rd Convolution layer\n",
        "model.add(Conv2D(512,(3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# 4th Convolution layer\n",
        "model.add(Conv2D(512,(3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Flattening\n",
        "model.add(Flatten())\n",
        "\n",
        "# Fully connected layer 1st layer\n",
        "model.add(Dense(256))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Fully connected layer 2nd layer\n",
        "model.add(Dense(512))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "opt = Adam(lr=0.0001)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RjlSzfB6yr2"
      },
      "source": [
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vS0WrFq-60Vv",
        "outputId": "ecf12c79-3e83-40bb-b644-6f47bd6464b9"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=5\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "696/696 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9988WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "696/696 [==============================] - 66s 92ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.0464 - val_accuracy: 0.9859\n",
            "Epoch 2/5\n",
            "696/696 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9989WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "696/696 [==============================] - 64s 92ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.1117 - val_accuracy: 0.9779\n",
            "Epoch 3/5\n",
            "696/696 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9989WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "696/696 [==============================] - 65s 93ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0135 - val_accuracy: 0.9954\n",
            "Epoch 4/5\n",
            "696/696 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9991WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "696/696 [==============================] - 65s 93ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.1721 - val_accuracy: 0.9634\n",
            "Epoch 5/5\n",
            "696/696 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9991WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "696/696 [==============================] - 65s 93ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.1783 - val_accuracy: 0.9675\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc32ae93a10>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDpoDPfzA4QB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95185158-6dd5-4480-d189-e94e76c5d7f9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMXOdCExAXDr",
        "outputId": "cb692712-27af-4891-da31-cf2fe68cbf57"
      },
      "source": [
        "model.save('drive/MyDrive/loweresModelTest')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: drive/MyDrive/loweresModelTest/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pL8RDAOBcQQ",
        "outputId": "ee3379fd-e9db-4294-ddee-08c56b21c4b5"
      },
      "source": [
        "#Show predicition for one image\n",
        "\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "CATEGORIES = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\", \"del\", \"nothing\", \"space\"]\n",
        "\n",
        "\n",
        "def prepare(filepath):\n",
        "    IMG_SIZE = 200\n",
        "    img_array = cv2.imread(filepath, 0)\n",
        "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1) \n",
        "\n",
        "\n",
        "#model = tf.keras.models.load_model(\"drive/MyDrive/loweresModelTest\")\n",
        "\n",
        "prediction = model.predict([prepare(\"./O_personaltest.jpg\")])\n",
        "\n",
        "print(CATEGORIES[int(np.argmax(prediction[0]))])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Z\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XK_xQs_6BJNk",
        "outputId": "ee735b61-4b45-4740-a6be-ca4160839fd1"
      },
      "source": [
        "prediction = model.predict([prepare(\"./A_personaltest.jpg\")])\n",
        "\n",
        "print(CATEGORIES[int(np.argmax(prediction[0]))])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C\n"
          ]
        }
      ]
    }
  ]
}